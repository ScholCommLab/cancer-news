{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2dc4b5cb25a4f6db070bff0e2e6dcfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import operator\n",
    "from itertools import chain\n",
    "from dateutil.parser import parse\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "tqdm_notebook().pandas()\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers to deal with various datatypes\n",
    "def JSONParser(data):\n",
    "    j = json.loads(data)\n",
    "    if j: \n",
    "        return j\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "converters={\"pmid\": str,\n",
    "       \"doi\": str,\n",
    "       \"title\": str,\n",
    "       \"journal\":str,\n",
    "       \"pub_year\":int,\n",
    "       \"pub_types\":JSONParser,\n",
    "       \"mesh_terms\":JSONParser,\n",
    "       \"grants\":JSONParser,\n",
    "       \"authors\":JSONParser,\n",
    "       \"author_affils\":JSONParser}\n",
    "\n",
    "# read in data\n",
    "df = pd.read_csv(\"../data/full_cancer_data.csv\", converters=converters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers to deal with various datatypes\n",
    "def JSONParser(data):\n",
    "    j = json.loads(data)\n",
    "    if j: \n",
    "        return j\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "converters={\"pmid\": str,\n",
    "            \"timestamp\": str,\n",
    "            \"am_response\":JSONParser}\n",
    "\n",
    "# read in data\n",
    "altmetric = pd.read_csv(\"../data/altmetrics/pubmed.csv\", converters=converters)\n",
    "altmetric = altmetric.set_index('pmid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['doi', 'title', 'journal', 'pub_year', 'pub_types', 'mesh_terms',\n",
       "       'grants', 'authors', 'author_affils'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deduplicate !!still need to look into that!!\n",
    "df = df[~df.pmid.duplicated(keep='first')]\n",
    "df = df.set_index(\"pmid\")\n",
    "df = df[df['pub_year'] == 2016]\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PubMed articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create MeSH desc and qual dummies\n",
    "\n",
    "Terms in the selected subtrees of a top 13 MeSH descriptor are aggregated as top-level terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_top13 =  [\"Urinary Bladder Neoplasms\",\n",
    "            \"Breast Neoplasms\",\n",
    "            \"Colorectal Neoplasms\",\n",
    "            \"Endometrial Neoplasms\",\n",
    "            \"Kidney Neoplasms\",\n",
    "            \"Leukemia\",\n",
    "            \"Liver Neoplasms\",\n",
    "            \"Lung Neoplasms\",\n",
    "            \"Melanoma\",\n",
    "            \"Lymphoma, Non-Hodgkin\",\n",
    "            \"Pancreatic Neoplasms\",\n",
    "            \"Prostatic Neoplasms\",\n",
    "            \"Thyroid Neoplasms\"]\n",
    "\n",
    "mesh_qual = [\"diagnosis\",\n",
    "             \"diagnostic imaging\",\n",
    "             \"mortality\",\n",
    "             \"therapy\",\n",
    "             \"diet therapy\",\n",
    "             \"drug therapy\",\n",
    "             \"nursing\",\n",
    "             \"prevention & control\",\n",
    "             \"radiotherapy\",\n",
    "             \"rehabilitation\",\n",
    "             \"surgery\",\n",
    "             \"transplantation\"]\n",
    "\n",
    "funding_types = [\"Research Support, American Recovery and Reinvestment Act\",\n",
    "                 \"Research Support, N.I.H., Extramural\",\n",
    "                 \"Research Support, N.I.H., Intramural\",\n",
    "                 \"Research Support, Non-U.S. Gov't\",\n",
    "                 \"Research Support, U.S. Gov't, Non-P.H.S.\",\n",
    "                 \"Research Support, U.S. Gov't, P.H.S.\",\n",
    "                 \"Research Support, U.S. Government\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare MeSH terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = {}\n",
    "numbers = {}\n",
    " \n",
    "meshFile = '../data/mesh_2018/d2018.bin'\n",
    "with open(meshFile, mode='r') as file:\n",
    "    mesh = file.readlines()\n",
    "    \n",
    "for line in mesh:\n",
    "    meshTerm = re.search('MH = (.+)$', line)\n",
    "    if meshTerm:\n",
    "        term = meshTerm.group(1)\n",
    "    meshNumber = re.search('MN = (.+)$', line)\n",
    "    if meshNumber:\n",
    "        number = meshNumber.group(1)\n",
    "        if number == None:\n",
    "            print(\"yes\")\n",
    "        numbers[number] = term\n",
    "        if term in terms:\n",
    "            terms[term] = terms[term] + ' ' + number\n",
    "        else:\n",
    "            terms[term] = number\n",
    "            \n",
    "# only use disease mesh terms\n",
    "c_keys = [key for key in sorted(list(numbers.keys())) if key[0] == \"C\"]\n",
    "\n",
    "# Create list of relevant meshterms for top 13 terms\n",
    "lookups = {}\n",
    "for t in mesh_top13:\n",
    "    x = []\n",
    "    for subnr in str.split(terms[t], \" \"):\n",
    "        x.extend([str.lower(numbers[key]) for key in c_keys if subnr in key])\n",
    "    lookups[t] = set(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dummy variables for MeSH, funding, and news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = df[['doi','title','pub_year', 'mesh_terms', 'pub_types']]\n",
    "add_cols = ['news_mention', 'news_count']\n",
    "out = pd.concat([out,\n",
    "                 altmetric['am_response'],\n",
    "                 pd.DataFrame(np.zeros((28372, 13), dtype=bool), index=out.index, columns=mesh_top13, dtype=bool),\n",
    "                 pd.DataFrame(np.zeros((28372, 12), dtype=bool), index=out.index, columns=mesh_qual, dtype=bool),\n",
    "                 pd.DataFrame(np.zeros((28372, 7), dtype=bool), index=out.index, columns=funding_types, dtype=bool),\n",
    "                 pd.DataFrame(np.zeros((28372, len(add_cols)), dtype=bool), index=out.index, columns=add_cols, dtype=bool)\n",
    "                ],\n",
    "                axis=1, join_axes=[out.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e155987ce29a4af98c7508ca4f8be42c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=28372), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def create_dummies(row):\n",
    "    # create dummies for mesh terms\n",
    "    if row.mesh_terms:\n",
    "        for mt,mqs in row.mesh_terms.items():\n",
    "            for topterm, subterms in lookups.items():\n",
    "                if mt in subterms:\n",
    "                    row[topterm] = True\n",
    "                for mq in mqs:\n",
    "                    if mq in mesh_qual:\n",
    "                        row[mq] = True\n",
    "                        \n",
    "    # create dummies for funding type\n",
    "    if row.pub_types:\n",
    "        for funding in funding_types:\n",
    "            if funding in row.pub_types:\n",
    "                row[funding] = True\n",
    "    \n",
    "    # count news mentions\n",
    "    try:\n",
    "        row['news_count'] = row['am_response']['counts']['news']['posts_count']\n",
    "        row['news_mention'] = True\n",
    "    except:\n",
    "        None\n",
    "    return row\n",
    "\n",
    "out = out.progress_apply(create_dummies, axis=1)\n",
    "\n",
    "# convert bool to float columns\n",
    "out[mesh_qual+mesh_top13+funding_types+add_cols] = out[mesh_qual+mesh_top13+funding_types+add_cols].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[['doi', 'pub_year', 'title', 'news_mention', 'news_count']].to_csv(\"metadata_and_news.csv\")\n",
    "out[mesh_top13].to_csv(\"mesh_term_dummies.csv\")\n",
    "out[mesh_qual].to_csv(\"mesh_subterm_dummies.csv\")\n",
    "out[funding_types].to_csv(\"funding_dummies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmids = []\n",
    "news_mentions = []\n",
    "\n",
    "for pmid, row in altmetric[~altmetric.am_response.isnull()].iterrows():\n",
    "    try:\n",
    "        news_mentions.append(row['am_response']['posts']['news'])\n",
    "        pmids.append(pmid)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "article_pmids = []\n",
    "venue_name = []\n",
    "venue_url = []\n",
    "date = []\n",
    "summary = []\n",
    "title = []\n",
    "url = []\n",
    "\n",
    "for pmid, nms in zip(pmids, news_mentions):\n",
    "    for nm in nms:\n",
    "        article_pmids.append(pmid)\n",
    "        venue_name.append(nm['author']['name'])\n",
    "        venue_url.append(nm['author']['url'])\n",
    "        date.append(str(parse(nm['posted_on'])))\n",
    "        try:\n",
    "            summary.append(nm['summary'])\n",
    "        except:\n",
    "            summary.append(None)\n",
    "        try:\n",
    "            title.append(nm['title'])\n",
    "        except:\n",
    "            title.append(None)\n",
    "        url.append(nm['url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export news coverage details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_out = pd.DataFrame({\n",
    "    'pmid': article_pmids,\n",
    "    'venue_name': venue_name,\n",
    "    'venue_url': venue_url,\n",
    "    'date': date,\n",
    "    'summary': summary,\n",
    "    'title': title,\n",
    "    'url': url\n",
    "})\n",
    "\n",
    "news_out.to_csv('news_coverage_details.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "altmetrics",
   "language": "python",
   "name": "altmetrics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
